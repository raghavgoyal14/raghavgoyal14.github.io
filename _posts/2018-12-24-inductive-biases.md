---
layout: post
<!-- date: 2018-12-24 -->
comments: true
title: "Inductive biases"
---

## Note: This is work in progress!

Most of the DL movement is geared towards engineering inductive biases that capture statistical structure present in data to get better towards the objective.

ML still heavily relies on statistical learning theory (not causality)

![mygif-2]({{site.url}}/assets/inductive-biases/dexter-judea-pearl.jpg)

Since AutoML (or genetic evolution) are not there to help you given our short life span, encoding inductive biases forms an inevitable part of the job of the peeps working in today's’ ML environment -- which is equally empowering and sad at the same time!

*C’mon make of the universe - do your thing!*

While reading papers and keeping myself up-to-date with the recent advancements in DL, I usually find myself different forms of “tricks” encoded in architecture, optimisation process, that just works and sometimes is the answer to research becoming successful.

*I’m a better AI engineer than you coz I have empirically-proven better inductive biases than you -- said no one ever! *

But wait, is there a guide to such biases?
I believe democratization of DL stack is on its right track with frameworks such as PyTorch, Keras, but can we democratise know-how of inductive biases in general?

I come from a CV background and will summarise some of the biases that just took off either
To kill a dataset
To make something work

My own experience regarding temporal footprint in video classification architectures!
CNN: boring! *someone trying to explain CNN to me. C’mon it’s 2019 not 2012!*
Graph Neural Networks - relational nets, attention nets, 
FiLM
VAE reparameterization trick, GANs loss manifold
World model - multiple modes Gaussian for Future
Dialog - Memory Nets?
Object detection - anchor boxes 
Uber CoordConv

Data engineering:
Balancing in VQA?

## References
[1] ...

{% include disqus.html %}